{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IR relevance and query feedback expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'document': 0, 'mine': 0, 'tze': 0, 'kun': 0, 'aaryam': 0, 'guang': 0, 'retrieval': 1.0, 'hello': 1.3010299956639813, 'is': 0, 'world': 1.0}\n",
      "0.8467135327313104\n",
      "====================\n",
      "('hello', 1.862886248373993)\n",
      "('world', 1.6666666666666667)\n",
      "('retrieval', 0.375)\n",
      "('document', 0.375)\n",
      "('aaryam', 0.2916666666666667)\n",
      "('tze', 0)\n",
      "('mine', 0)\n",
      "('kun', 0)\n",
      "('is', 0)\n",
      "('guang', 0)\n"
     ]
    }
   ],
   "source": [
    "import re, math\n",
    "from collections import Counter\n",
    "import nltk\n",
    "\n",
    "\n",
    "# Assumption 1: We have the entire vocab for documents at least\n",
    "# Assumption 2: Relevant and irrelevant documents were chosen by some method\n",
    "# Assumption 3: User's intial query at least partially works\n",
    "# Assumption 4: Term distribution of non-relevant documents are sufficiently distinct from relevant ones\n",
    "\n",
    "query = \"hello world\"\n",
    "relevant_documents = [\"hello world retrieval hello\", \"hello world document aaryam\"]\n",
    "non_relevant_documents = [\"aaryam\", \"tze guang kun is fab\", \"world is mine\"]\n",
    "universal_vocab = {\"hello\", \"world\", \"retrieval\", \"document\", \"world\", \"is\", \"mine\", \"tze\", \"guang\", \"kun\", \"aaryam\"}\n",
    "\n",
    "ALPHA = 1\n",
    "BETA = 0.75\n",
    "GAMMA = 0.25\n",
    "    \n",
    "# Generate the table for doc or query with tf no idf\n",
    "def generateTable (doc):\n",
    "    words = nltk.word_tokenize(doc)\n",
    "    table = Counter(nltk.word_tokenize(doc))\n",
    "    vector = {}\n",
    "    for term in universal_vocab:\n",
    "        if (term in table):\n",
    "            # TF no IDF\n",
    "            vector[term] = 1 + math.log10(table[term])\n",
    "        else:\n",
    "            vector[term]= 0\n",
    "        \n",
    "    return vector\n",
    "\n",
    "\n",
    "def cosineCal(h1, h2):\n",
    "    sum = 0\n",
    "    s1 = 0\n",
    "    s2 = 0\n",
    "    for t in h1:\n",
    "        sum += h1[t]*h2[t]\n",
    "        s1 += math.pow(h1[t],2)\n",
    "        s2 += math.pow(h2[t],2)\n",
    "    s1 = math.sqrt(s1)\n",
    "    s2 = math.sqrt(s2)\n",
    "    value = sum/(s1*s2)\n",
    "    return value\n",
    "\n",
    "\n",
    "print (generateTable(relevant_documents[0]))\n",
    "print (cosineCal(generateTable(relevant_documents[0]), generateTable(query)))\n",
    "\n",
    "# TODO: Verify if this is the right method to obtaining the centroid\n",
    "def getCentroid(docs_list):\n",
    "    total_sum = {}\n",
    "    for doc in docs_list:\n",
    "        score_table = generateTable(doc)\n",
    "        for term in score_table:\n",
    "            if term in total_sum:\n",
    "                total_sum[term] += score_table[term]\n",
    "            else:\n",
    "                total_sum[term] = score_table[term]\n",
    "    \n",
    "    centroid = {}\n",
    "    for term in total_sum:\n",
    "        centroid[term] = total_sum[term]/len(docs_list)\n",
    "    \n",
    "    return centroid\n",
    "\n",
    "def getRocchio (original_query):\n",
    "    original_query_space = generateTable(original_query)\n",
    "    centroid_relevant = getCentroid(relevant_documents)\n",
    "    centroid_non_relevant = getCentroid(non_relevant_documents)\n",
    "    query_modified = {}\n",
    "    for term in universal_vocab:\n",
    "        query_modified[term] = ALPHA*original_query_space[term] + \\\n",
    "        BETA*centroid_relevant[term] - \\\n",
    "        GAMMA*centroid_non_relevant[term]\n",
    "        \n",
    "        # Set it to zero if it is negative\n",
    "        if (query_modified[term] < 0):\n",
    "            query_modified[term] = 0\n",
    "        \n",
    "    return query_modified\n",
    "\n",
    "print (\"====================\")\n",
    "\n",
    "for term in sorted(getRocchio(query).items(), key = lambda kv:(kv[1], kv[0]), reverse=True):\n",
    "    print (term)\n",
    "# Now we can see the scores of some other terms which could make up the query too"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Further steps:\n",
    "\n",
    "1. Queries which makes sense will then be parsed back to the query, yielding more documents\n",
    "2. User will then decide what's relevant and what's not relevant again\n",
    "3. Process will repeat\n",
    "\n",
    "\n",
    "##### Pseudo Relevance feedbace\n",
    "Blind feedback means that we assume the top k documents are relevant. It works really well on average but can go horribly wrong for some queries."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
