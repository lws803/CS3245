{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IR relevance and query feedback expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kun': 0, 'hello': 1.3010299956639813, 'document': 0, 'tze': 0, 'guang': 0, 'aaryam': 0, 'world': 1.0, 'retrieval': 1.0, 'mine': 0, 'is': 0}\n",
      "====================\n",
      "('hello', 1.862886248373993)\n",
      "('world', 1.7)\n",
      "('retrieval', 0.375)\n",
      "('document', 0.375)\n",
      "('aaryam', 0.325)\n",
      "('tze', 0)\n",
      "('mine', 0)\n",
      "('kun', 0)\n",
      "('is', 0)\n",
      "('guang', 0)\n"
     ]
    }
   ],
   "source": [
    "import re, math\n",
    "from collections import Counter\n",
    "import nltk\n",
    "\n",
    "\n",
    "# Assumption 1: We have the entire vocab for documents at least\n",
    "# Assumption 2: Relevant and irrelevant documents were chosen by some method\n",
    "# Assumption 3: User's intial query at least partially works\n",
    "# Assumption 4: Term distribution of non-relevant documents are sufficiently distinct from relevant ones\n",
    "\n",
    "query = \"hello world\"\n",
    "relevant_documents = [\"hello world retrieval hello\", \"hello world document aaryam\"]\n",
    "non_relevant_documents = [\"aaryam\", \"tze guang kun is fab\", \"world is mine\"]\n",
    "universal_vocab = {\"hello\", \"world\", \"retrieval\", \"document\", \"world\", \"is\", \"mine\", \"tze\", \"guang\", \"kun\", \"aaryam\"}\n",
    "\n",
    "ALPHA = 1\n",
    "BETA = 0.75\n",
    "GAMMA = 0.15\n",
    "    \n",
    "# Generate the table for doc or query with tf no idf\n",
    "def generateTable (doc):\n",
    "    words = nltk.word_tokenize(doc)\n",
    "    table = Counter(nltk.word_tokenize(doc))\n",
    "    vector = {}\n",
    "    for term in universal_vocab:\n",
    "        if (term in table):\n",
    "            # TF no IDF\n",
    "            vector[term] = 1 + math.log10(table[term])\n",
    "        else:\n",
    "            vector[term]= 0\n",
    "        \n",
    "    return vector\n",
    "\n",
    "\n",
    "print (generateTable(relevant_documents[0]))\n",
    "\n",
    "# TODO: Verify if this is the right method to obtaining the centroid\n",
    "def getCentroid(docs_list):\n",
    "    total_sum = {}\n",
    "    for doc in docs_list:\n",
    "        score_table = generateTable(doc)\n",
    "        for term in score_table:\n",
    "            if term in total_sum:\n",
    "                total_sum[term] += score_table[term]\n",
    "            else:\n",
    "                total_sum[term] = score_table[term]\n",
    "    \n",
    "    centroid = {}\n",
    "    for term in total_sum:\n",
    "        centroid[term] = total_sum[term]/len(docs_list)\n",
    "    \n",
    "    return centroid\n",
    "\n",
    "def getRocchio (original_query):\n",
    "    original_query_space = generateTable(original_query)\n",
    "    centroid_relevant = getCentroid(relevant_documents)\n",
    "    centroid_non_relevant = getCentroid(non_relevant_documents)\n",
    "    query_modified = {}\n",
    "    for term in universal_vocab:\n",
    "        query_modified[term] = ALPHA*original_query_space[term] + \\\n",
    "        BETA*centroid_relevant[term] - \\\n",
    "        GAMMA*centroid_non_relevant[term]\n",
    "        \n",
    "        # Set it to zero if it is negative\n",
    "        if (query_modified[term] < 0):\n",
    "            query_modified[term] = 0\n",
    "        \n",
    "    return query_modified\n",
    "\n",
    "print (\"====================\")\n",
    "\n",
    "for term in sorted(getRocchio(query).items(), key = lambda kv:(kv[1], kv[0]), reverse=True):\n",
    "    print (term)\n",
    "# Now we can see the scores of some other terms which could make up the query too"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Effect of tuning gamma, alpha, beta\n",
    "- Higher `BETA` and `GAMMA` if we want to trust the judged documents more - do so only if we have a lot of judged documents\n",
    "- Higher `ALPHA` means we trust the query terms more\n",
    "- Higher `BETA` than `GAMMA` means we favour more positive feedback, as it is more valuable than negative ones.\n",
    "\n",
    "Common params: `ALPHA = 1`, `BETA = 0.75`, `GAMMA = 0.15`  \n",
    "eg. `aaryam` has a **lower score** compared to `retrieval` and `document` as it is in the non relevant docs as well.\n",
    "\n",
    "##### Further steps:\n",
    "\n",
    "1. Queries which makes sense will then be parsed back to the query, yielding more documents\n",
    "2. User will then decide what's relevant and what's not relevant again\n",
    "3. Process will repeat\n",
    "\n",
    "\n",
    "##### Pseudo Relevance feedbace\n",
    "Blind feedback means that we assume the top k documents are relevant. It works really well on average but can go horribly wrong for some queries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thesaurus based query expansion\n",
    "\n",
    "- For each term in a query, expand the query with synonyms and related words eg. feline -> cat\n",
    "- Generally increases recall, but may decrease precision when terms are ambiguous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('car.n.01')]\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "print (wn.synsets(\"motorcar\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automatic thesaurus generation\n",
    "\n",
    "- Generate thesaurus by analysing document\n",
    "- Assumption: Distributional similarity\n",
    "- i.e Two words are similar if they co-occur/ share same grammatical relations\n",
    "Compute using term-term similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true contemptible christian abundant few part mean careful puzzled\n",
      "mystifying passing curious loving wise doleful gamesome singular\n",
      "delightfully perilous fearless\n"
     ]
    }
   ],
   "source": [
    "from nltk.book import text1\n",
    "\n",
    "text1.similar(\"monstrous\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problems\n",
    "1. Term ambiguity may introduce irrelevant statistically correlated terms eg. Apple red fruit computer\n",
    "2. False positives: Words deemed similar are not especially opposites\n",
    "3. False negatives: Words deemed dissimilar that are similar"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
