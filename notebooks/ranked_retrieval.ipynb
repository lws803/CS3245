{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ranked retrieval\n",
    "\n",
    "Good for majority of users who wish to see results sorted by *relevance*.\n",
    "\n",
    "## Approach 1: Jaccard coefficient\n",
    "`Jaccard(A,B) = |A and B|/|A or B|`\n",
    "\n",
    "### Pros\n",
    "1. A and B dont have to be the same size\n",
    "2. Always assigns a number b/w 0 and 1.\n",
    "\n",
    "### Cons\n",
    "1. Does not consider term frequency (we want to distinguish which term has high frequency vs low frequency) - the more frequent the term, the higher the relevance *should be*.\n",
    "\n",
    "## Approach 2: Using term frequency and inverted document frequency\n",
    "\n",
    "`tf = frequency of term d appearing in document d`  \n",
    "Note: a document with 10x more freuency of this term does not mean that its 10x more relevant. (not proportional)\n",
    "\n",
    "### Log frequency weighting\n",
    "\n",
    "```\n",
    "If (tf > 0)\n",
    "    w = 1+log(tf)\n",
    "else\n",
    "    w = 0\n",
    "```\n",
    "\n",
    "Total score for a document-query pair:\n",
    "\n",
    "`score = sum(1+log(tf))` from all terms in query AND document\n",
    "\n",
    "### Document frequency\n",
    "\n",
    "Rationale: Rare terms are more informative than frequent terms. eg. stop words concept  \n",
    "`idf = log(N/df)`\n",
    "- df = document frequency of term t, number of documents that contain the term t\n",
    "- N is the total number of documents\n",
    "\n",
    "Rarest/ low frequency words will have a larger `idf` value.\n",
    "\n",
    "### Tf-idf weighting\n",
    "\n",
    "`W = (1+log(tf))*log(N/df)`\n",
    "\n",
    "#### Properties:\n",
    "1. Increases with number of occurences within a document\n",
    "2. Increases with rarity of the term in collection\n",
    "\n",
    "#### Total score\n",
    "\n",
    "`Score (q,d) = sum (tf-idf)` from all terms in query AND document\n",
    "\n",
    "#### Issues:\n",
    "1. We have a |V| dimensional space vector -> very large\n",
    "2. Very sparse vectors, most are zero\n",
    "3. No positional indexing and does not consider the ordering of words\n",
    "4. If we feed a query with wrong word, we will get nothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input you query: why hello there\n",
      "score for tf: 0\n",
      "score for idf: 0\n",
      "combined score: 0\n",
      "=======================================================================\n",
      "score for tf: 0\n",
      "score for idf: 0\n",
      "combined score: 0\n",
      "=======================================================================\n",
      "score for tf: 0\n",
      "score for idf: 0\n",
      "combined score: 0\n",
      "=======================================================================\n",
      "score for tf: 0\n",
      "score for idf: 0\n",
      "combined score: 0\n",
      "=======================================================================\n",
      "score for tf: 0\n",
      "score for idf: 0\n",
      "combined score: 0\n",
      "=======================================================================\n",
      "\n",
      "Final result:\n",
      "[(0, 5), (0, 4), (0, 3), (0, 2), (0, 1)]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import math\n",
    "\n",
    "\n",
    "docs = {1:\"who is aaryam, aaryam is a genius.\", \n",
    "        2: \"wilson is a hypocrite\", \n",
    "        3: \"tze guang is a guy who needs to chill is fab\",\n",
    "        4: \"TTGHCS will become a reality, all hail Tze Guang\",\n",
    "        5: \"Hit or miss, #road to 100 million for Pewds\"\n",
    "       }\n",
    "\n",
    "query = input(\"input you query: \")\n",
    "scores = {}\n",
    "doc_freq = {}\n",
    "doc_ranking = []\n",
    "\n",
    "# Find document frequency of each term\n",
    "for key in docs:\n",
    "    text = docs[key]\n",
    "    \n",
    "    for term in list(set(nltk.word_tokenize(text))):\n",
    "        if (term in doc_freq):\n",
    "            doc_freq[term] += 1\n",
    "        else:\n",
    "            doc_freq[term] = 1\n",
    "            \n",
    "\n",
    "for key in docs:\n",
    "    text = docs[key]\n",
    "    term_freq = {}\n",
    "    for term in nltk.word_tokenize(text):\n",
    "        if (term not in term_freq):\n",
    "            term_freq[term] = 1\n",
    "        else:\n",
    "            term_freq[term] += 1\n",
    "\n",
    "    intersect = list(set(nltk.word_tokenize(text)) & set(nltk.word_tokenize(query)))\n",
    "    \n",
    "    # tf\n",
    "    score_tf = sum(1 + math.log(term_freq[term]) for term in intersect)\n",
    "    \n",
    "    # idf\n",
    "    score_idf = sum(math.log(len(docs)/float(doc_freq[term])) for term in intersect)\n",
    "        \n",
    "    print (\"score for tf:\", score_tf)\n",
    "    print (\"score for idf:\", score_idf)\n",
    "    print (\"combined score:\", score_tf*score_idf)\n",
    "    doc_ranking.append((score_tf*score_idf, key))\n",
    "    print (\"=======================================================================\")\n",
    "\n",
    "print (\"\\nFinal result:\")\n",
    "doc_ranking.sort(reverse=True)\n",
    "print (doc_ranking)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 3: text2vec cosine similarity model\n",
    "\n",
    "\n",
    "Convert both query and document words into vectors. Perform tf.idf cosine similarity on them.\n",
    "\n",
    "### Why euclidean distance is a bad idea\n",
    "\n",
    "Distances in euclidean space are too large.  \n",
    "Eg. a text with similar words similar distribution but one has much more word count. Their distances is very far apart even though they are similar in relevance\n",
    "\n",
    "### Cosine similarity\n",
    "Rank documents based on the angle distance to query.\n",
    "\n",
    "#### Pros\n",
    "\n",
    "1. Vectors are length normalised - making them comparable across different vectors despite their original lengths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enter your query: this sentence is a foo bar sentence\n",
      "Cosine score: 0.8347948681581757\n"
     ]
    }
   ],
   "source": [
    "import re, math\n",
    "from collections import Counter\n",
    "import nltk\n",
    "\n",
    "def get_cosine(vec1, vec2):\n",
    "    intersection = set(vec1.keys()) & set(vec2.keys())\n",
    "    numerator = sum([vec1[x] * vec2[x] for x in intersection]) \n",
    "    # Tip: Perform these operations as matrix operations using numpy\n",
    "\n",
    "    sum1 = sum([vec1[x]**2 for x in vec1.keys()])\n",
    "    sum2 = sum([vec2[x]**2 for x in vec2.keys()])\n",
    "    denominator = math.sqrt(sum1) * math.sqrt(sum2) # This makes it length normalised\n",
    "\n",
    "    if not denominator:\n",
    "        return 0.0\n",
    "    else:\n",
    "        return float(numerator) / denominator\n",
    "\n",
    "def text_to_vector_ltc(text):\n",
    "    words = nltk.word_tokenize(text)\n",
    "    term_freq = Counter(words)\n",
    "    term_score = {}\n",
    "\n",
    "    # tf\n",
    "    for term in list(set(words)):\n",
    "        term_score[term] = 1 + math.log(term_freq[term])\n",
    "    \n",
    "    # idf\n",
    "    for term in list(set(words)):\n",
    "        term_score[term] *= math.log(len(words)/float(term_freq[term])) \n",
    "        # use len(words) as N to simulate each word as its own document\n",
    "    return term_score\n",
    "\n",
    "\n",
    "def text_to_vector_lnc(text):\n",
    "    words = nltk.word_tokenize(text)\n",
    "    term_freq = Counter(words)\n",
    "    term_score = {}\n",
    "\n",
    "    # tf\n",
    "    for term in list(set(words)):\n",
    "        term_score[term] = 1 + math.log(term_freq[term])\n",
    "    \n",
    "    # No idf\n",
    "    return term_score\n",
    "\n",
    "\n",
    "\n",
    "query = input(\"enter your query: \")\n",
    "text2 = 'this sentence is similar to a foo bar sentence .'\n",
    "\n",
    "vector1 = text_to_vector_ltc(query)\n",
    "vector2 = text_to_vector_lnc(text2)\n",
    "\n",
    "cosine = get_cosine(vector1, vector2)\n",
    "\n",
    "print ('Cosine score:', cosine) # the larger the number, the more relevant\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional stuff\n",
    "\n",
    "Weighting can differ in queries vs document. One very popular weighting scheme is the `lnc.ltc` scheme.\n",
    "\n",
    "### Document side (lnc):\n",
    "- l: logarithmic tf\n",
    "- n: no idf\n",
    "- c: cosine normalisation\n",
    "\n",
    "### Query side (ltc):\n",
    "- l: logarithmic tf\n",
    "- t: logarithmic idf\n",
    "- c: cosine normalisation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
