{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unigram method for counting probabilities\n",
    "\n",
    "## Differences b/w unigram method and true ngram method\n",
    "1. Unigram method uses AND property of probability: just multiply the probabilities of words\n",
    "2. True NGram method uses conditional probability `P(abcd) = P(d|abc) * P(abc)`  \n",
    "This is how we obtain the probability by using a chain of conditional probabilities in **bigram**  \n",
    "`P('There was heavy rain') ~ P('There')P('was'|'There')P('heavy'|'was')P('rain'|'heavy')`\n",
    "3. True NGram will output very discreet values especially for `P(d|abc)` as `Freq(abcd)` and `Freq(abc)` could be same number (if data is sparse)\n",
    "4. Use the true NGram method only when we have enough data sets.\n",
    "\n",
    "\n",
    "## Why do we use add-one smoothing\n",
    "To distribute some probability from seen words to unseen words. We pretend that everything is seen at least once. However, add-one smoothing gives a false impression of the index we create (hence why we don't perform add-k smoothing for instance).\n",
    "  \n",
    "If language model is constructed from large number of observations\n",
    "- If small vocab but large observations, there will be no significant change of distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_collection_PC = [\"I Don't Want To Go\", \"A Groovy Kind Of Love\", \"You Can't Hurry Love\", \"This Must Be Love\", \"Take Me With You\"]\n",
    "text_collection_AS = [\"All Out Of Love\", \"Here I Am\", \"I Remember Love\", \"Love Is All\", \"Don't Tell Me\"]\n",
    "\n",
    "vocab = {} # We store vocab here to count the universal number of different vocabs available****\n",
    "text_collection_PC_freq = {}\n",
    "text_collection_AS_freq = {}\n",
    "total_text_collection_PC_freq = 0\n",
    "total_text_collection_AS_freq = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declare our variabels and song titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formula for counting the probability\n",
    "\n",
    "`freq(word)/(total_freq_of_intended_dictionary + length(vocab))`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settle the Air Supply frequency first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for titles in text_collection_AS:\n",
    "    for word in titles.split():\n",
    "        vocab[word] = 1\n",
    "        total_text_collection_AS_freq += 1\n",
    "        if (word not in text_collection_AS_freq):\n",
    "            text_collection_AS_freq[word] = 1\n",
    "        else:\n",
    "            text_collection_AS_freq[word] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settle the Phil Collins frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for titles in text_collection_PC:\n",
    "    for word in titles.split():\n",
    "        vocab[word] = 1\n",
    "        total_text_collection_PC_freq += 1\n",
    "\n",
    "        if (word not in text_collection_PC_freq):\n",
    "            text_collection_PC_freq[word] = 1\n",
    "        else:\n",
    "            text_collection_PC_freq[word] += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n",
      "Total for AS, including total vocab size:  42\n",
      "Total for PC, including total vocab size:  48\n",
      "==========================\n"
     ]
    }
   ],
   "source": [
    "print (len(vocab))\n",
    "print (\"Total for AS, including total vocab size: \", (total_text_collection_AS_freq + len(vocab)))\n",
    "print (\"Total for PC, including total vocab size: \", (total_text_collection_PC_freq + len(vocab)))\n",
    "print (\"==========================\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add the query text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"I Remember You\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate probability\n",
    "\n",
    "- We ignore the words that are not spotted in the dictionary\n",
    "- We also use the log space as probabilities can get really really small (this prevents underflow of floating point values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Air Supply -2.94546858513182\n",
      "Phil Collins -3.061452479087193\n"
     ]
    }
   ],
   "source": [
    "probability_AS = 0\n",
    "probability_PC = 0\n",
    "\n",
    "\n",
    "for word in query.split():\n",
    "    if (word in text_collection_PC_freq):\n",
    "        probability_PC += (math.log10(text_collection_PC_freq[word]) - math.log10(total_text_collection_PC_freq + len(vocab)))\n",
    "\n",
    "for word in query.split():\n",
    "    if (word in text_collection_AS_freq):\n",
    "        probability_AS += (math.log10(text_collection_AS_freq[word]) - math.log10(total_text_collection_AS_freq + len(vocab)))\n",
    "        \n",
    "print (\"Air Supply\", probability_AS)\n",
    "print (\"Phil Collins\", probability_PC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This title is from Phil Collins\n"
     ]
    }
   ],
   "source": [
    "if (probability_PC > probability_AS):\n",
    "    print (\"This title is from Air Supply\")\n",
    "else:\n",
    "    print (\"This title is from Phil Collins\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
