{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unigram method for counting probabilities\n",
    "\n",
    "## Differences b/w unigram method and true ngram method\n",
    "1. Unigram method uses AND property of probability: just multiply the probabilities of words\n",
    "2. True NGram method uses conditional probability `P(abcd) = P(d|abc) * P(abc)`  \n",
    "This is how we obtain the probability by using a chain of conditional probabilities in **bigram**  \n",
    "`P('There was heavy rain') ~ P('There')P('was'|'There')P('heavy'|'was')P('rain'|'heavy')`\n",
    "3. True NGram will output very discreet values especially for `P(d|abc)` as `Freq(abcd)` and `Freq(abc)` could be same number (if data is sparse)\n",
    "4. Use the true NGram method only when we have enough data sets.\n",
    "\n",
    "\n",
    "## Why do we use add-one smoothing\n",
    "To distribute some probability from seen words to unseen words. We pretend that everything is seen at least once. However, add-one smoothing gives a false impression of the index we create (hence why we don't perform add-k smoothing for instance).\n",
    "  \n",
    "If language model is constructed from large number of observations\n",
    "- If small vocab but large observations, there will be no significant change of distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_collection_PC = [\"I Don't Want To Go\", \"A Groovy Kind Of Love\", \"You Can't Hurry Love\", \"This Must Be Love\", \"Take Me With You\"]\n",
    "text_collection_AS = [\"All Out Of Love\", \"Here I Am\", \"I Remember Love\", \"Love Is All\", \"Don't Tell Me\"]\n",
    "\n",
    "vocab = {} # We store vocab here to count the universal number of different vocabs available****\n",
    "text_collection_PC_freq = {}\n",
    "text_collection_AS_freq = {}\n",
    "total_text_collection_PC_freq = 0\n",
    "total_text_collection_AS_freq = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declare our variabels and song titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formula for counting the probability\n",
    "\n",
    "`freq(word)/(total_freq_of_intended_dictionary + length(vocab))`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settle the Air Supply frequency first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for titles in text_collection_AS:\n",
    "    for word in titles.split():\n",
    "        vocab[word] = 1\n",
    "        total_text_collection_AS_freq += 1\n",
    "        if (word not in text_collection_AS_freq):\n",
    "            text_collection_AS_freq[word] = 1\n",
    "        else:\n",
    "            text_collection_AS_freq[word] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settle the Phil Collins frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for titles in text_collection_PC:\n",
    "    for word in titles.split():\n",
    "        vocab[word] = 1\n",
    "        total_text_collection_PC_freq += 1\n",
    "\n",
    "        if (word not in text_collection_PC_freq):\n",
    "            text_collection_PC_freq[word] = 1\n",
    "        else:\n",
    "            text_collection_PC_freq[word] += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n",
      "Total for AS, including total vocab size:  42\n",
      "Total for PC, including total vocab size:  48\n",
      "==========================\n"
     ]
    }
   ],
   "source": [
    "print (len(vocab))\n",
    "print (\"Total for AS, including total vocab size: \", (total_text_collection_AS_freq + len(vocab)))\n",
    "print (\"Total for PC, including total vocab size: \", (total_text_collection_PC_freq + len(vocab)))\n",
    "print (\"==========================\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add the query text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"I Remember You\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate probability\n",
    "\n",
    "- We ignore the words that are not spotted in the dictionary\n",
    "- We also use the log space as probabilities can get really really small (this prevents underflow of floating point values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'text_collection_PC_freq' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-5da3d2acc4e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext_collection_PC_freq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mprobability_PC\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog10\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_collection_PC_freq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog10\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_text_collection_PC_freq\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'text_collection_PC_freq' is not defined"
     ]
    }
   ],
   "source": [
    "probability_AS = 0\n",
    "probability_PC = 0\n",
    "\n",
    "\n",
    "for word in query.split():\n",
    "    if (word in text_collection_PC_freq):\n",
    "        probability_PC += (math.log10(text_collection_PC_freq[word]) - math.log10(total_text_collection_PC_freq + len(vocab)))\n",
    "\n",
    "for word in query.split():\n",
    "    if (word in text_collection_AS_freq):\n",
    "        probability_AS += (math.log10(text_collection_AS_freq[word]) - math.log10(total_text_collection_AS_freq + len(vocab)))\n",
    "        \n",
    "print (\"Air Supply\", probability_AS)\n",
    "print (\"Phil Collins\", probability_PC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This title is from Phil Collins\n"
     ]
    }
   ],
   "source": [
    "if (probability_PC > probability_AS):\n",
    "    print (\"This title is from Air Supply\")\n",
    "else:\n",
    "    print (\"This title is from Phil Collins\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
