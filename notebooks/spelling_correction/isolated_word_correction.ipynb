{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Isolated word correction - tolerant retrieval\n",
    "\n",
    "NO consideration for context. Returns the words in the lexicon closest to the word we're checking.\n",
    "\n",
    "## Types\n",
    "1. Edit distance\n",
    "2. Weighted edit distance\n",
    "3. ngram overlap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Edit distance\n",
    "See lecture notes, use DP grid to find out what is the cost we should set at each grid.  \n",
    "To find optimal paths, always look vertically from top to bottom. Telltale signs are a sudden drop in value from an increasing sequence from top to bottom. eg. `6555455, 4 is an optimal step`\n",
    "\n",
    "\n",
    "## Downsides\n",
    "1. Extremely slow as we need to perform edit distance for every single vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apple 7\n",
      "bag 6\n",
      "drawing 4\n",
      "listing 1\n",
      "linking 2\n",
      "living 2\n",
      "lighting 1\n",
      "orange 6\n",
      "walking 4\n",
      "zoo 7\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "mistake = \"ligting\"\n",
    "\n",
    "words = ['apple', 'bag', 'drawing', 'listing', 'linking', 'living', 'lighting', 'orange', 'walking', 'zoo']\n",
    "\n",
    "for word in words:\n",
    "    ed = nltk.edit_distance(mistake, word)\n",
    "    print(word, ed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weighted edit distance\n",
    "\n",
    "Meant to capture keyboard or OCR errors. Takes into consideration of keyboards  \n",
    "replacing `m` by `n` has a smaller edit distance than `q` since `q` is further away from `m` or `n`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jaccard distance\n",
    "\n",
    "A tool for measuring the similarity based on set theory\n",
    "\n",
    "`|X AND Y|/|X OR Y|`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apple 0.875\n",
      "bag 0.8571428571428571\n",
      "drawing 0.6666666666666666\n",
      "listing 0.16666666666666666\n",
      "linking 0.3333333333333333\n",
      "living 0.3333333333333333\n",
      "lighting 0.16666666666666666\n",
      "orange 0.7777777777777778\n",
      "walking 0.5\n",
      "zoo 1.0\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "mistake = \"ligting\"\n",
    "\n",
    "words = ['apple', 'bag', 'drawing', 'listing', 'linking', 'living', 'lighting', 'orange', 'walking', 'zoo']\n",
    "\n",
    "for word in words:\n",
    "    jd = nltk.jaccard_distance(set(mistake), set(word))\n",
    "    print(word, jd)\n",
    "    \n",
    "# Least means better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ngram overlap\n",
    "\n",
    "### Steps\n",
    "1. Enumerate all the ngrams in the query string as well as in the lexicon\n",
    "2. Use the ngram index to retrieve all the lexicon terms matching any of the query terms - AND operators\n",
    "3. Threshold by number of matching ngrams\n",
    "\n",
    "\n",
    "### Formula - Jaccard coefficient\n",
    "`|X AND Y|/|X OR Y|`\n",
    "\n",
    "`X` and `Y` are ngrams of the query terms. They are sets.\n",
    "\n",
    "\n",
    "#### Example\n",
    "Suppose we have `X` = November and `Y` = December.  \n",
    "3 trigrams overlap out of 9 (total) == `emb`, `mbe`, `ber`.  \n",
    "Universal set: `nov`, `ove`, `vem`, `emb`, `mbe`, `ber`, `dec`, `ece`, `cem`\n",
    "  \n",
    "##### Calculating jaccard coefficient\n",
    "`3/9`  \n",
    "We can also threshold the minimum matches before actually calculating the jaccard coefficient. eg. minimum `2 matches`\n",
    "\n",
    "\n",
    "### Matching bigrams\n",
    "eg. given the word `lord` - we wish to identify words matching to *2 or more* of its 3 bigrams\n",
    "\n",
    "- `lo` - alone -> lord -> sloth\n",
    "- `or` - border -> lord -> morbid\n",
    "- `rd` - ardent -> border -> card\n",
    "\n",
    "Therefore, `border` and `lord` shall be returned\n",
    "\n",
    "\n",
    "### Handling spelling mistakes caused by transpositions\n",
    "Although matching ngrams wont match transpositions, there is still a potential for the *slightly* transposed word to be considered especially if the word is long and the other ngrams matches those in the ngram word list. *However*, if the word is short or majority of the word is transposed, then we will be unlikely to get a match especially if **threshold is set to a high number**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3076923076923077 Jaccard Distance between sent1 and sent2 with ngram 2\n",
      "0.4918032786885246 Jaccard Distance between sent1 and sent3 with ngram 2\n",
      "0.10416666666666667 Jaccard Distance between sent1 and sent4 with ngram 2\n",
      "0.8333333333333334 Jaccard Distance between sent1 and sent5 with ngram 2\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "sent1 = \"It might help to re-install Python if possible.\"\n",
    "sent2 = \"It can help to install Python again if possible.\"\n",
    "sent3 = \"It can be so helpful to reinstall C++ if possible.\"\n",
    "sent4 = \"help It possible Python to re-install if might.\" # This has the same words as sent1 with a different order.\n",
    "sent5 = \"I love Python programming.\"\n",
    "\n",
    "\n",
    "ng1_chars = set(nltk.ngrams(sent1, n=2))\n",
    "ng2_chars = set(nltk.ngrams(sent2, n=2))\n",
    "ng3_chars = set(nltk.ngrams(sent3, n=2))\n",
    "ng4_chars = set(nltk.ngrams(sent4, n=2))\n",
    "ng5_chars = set(nltk.ngrams(sent5, n=2))\n",
    "\n",
    "jd_sent_1_2 = nltk.jaccard_distance(ng1_chars, ng2_chars)\n",
    "jd_sent_1_3 = nltk.jaccard_distance(ng1_chars, ng3_chars)\n",
    "jd_sent_1_4 = nltk.jaccard_distance(ng1_chars, ng4_chars)\n",
    "jd_sent_1_5 = nltk.jaccard_distance(ng1_chars, ng5_chars)\n",
    "\n",
    "print(jd_sent_1_2, \"Jaccard Distance between sent1 and sent2 with ngram 2\")\n",
    "print(jd_sent_1_3, \"Jaccard Distance between sent1 and sent3 with ngram 2\")\n",
    "print(jd_sent_1_4, \"Jaccard Distance between sent1 and sent4 with ngram 2\")\n",
    "print(jd_sent_1_5, \"Jaccard Distance between sent1 and sent5 with ngram 2\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
