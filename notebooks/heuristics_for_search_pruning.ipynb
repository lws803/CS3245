{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruning the ranking and search space with heuristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faster cosine scoring\n",
    "scores = {}\n",
    "def get_cosine (query):\n",
    "    for doc in documents:\n",
    "        scores[doc] = 0\n",
    "    for term in query.split():\n",
    "        weight_q = weight(term, query) # Find weight of query term\n",
    "        postings_list = get_postings(term)\n",
    "        \n",
    "        for doc, tf in postings_list:\n",
    "            scores[doc] += weight (term, doc) # Find tf-idf of doc\n",
    "            # Notice we dont multiply by the terms in the query at all\n",
    "    output = []\n",
    "    for doc in scores:\n",
    "        scores[doc] /= len(doc) # Normalisation\n",
    "        output.append((-scores[doc], doc))\n",
    "    output.sort()\n",
    "    \n",
    "    return output # or choose to return top K only here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Efficient cosine ranking\n",
    "\n",
    "#### Find K docs in collection\n",
    "1. Dump all the docs primarily sorted by their cosine scores into heap\n",
    "2. Extract K documents\n",
    "\n",
    "#### Pros:\n",
    "This is faster than sorting as we can build heap in `O(N)` and extract with `O(KlogN)`\n",
    "\n",
    "#### Cons:\n",
    "We are still bottlenecked by the cosine calculation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Index elimination\n",
    "\n",
    "Extend `FastCosineScoring` to only consider documents\n",
    "1. containing many query terms\n",
    "2. with high idf query terms (rarer terms)\n",
    "\n",
    "#### High idf query terms only\n",
    "Stopwords will contribute very little to overall score for rank-ordering.\n",
    "\n",
    "##### Pros:\n",
    "- Postings of low idf terms have many docs -> these many docs get eliminated from contenders list\n",
    "- Similiar in spirit to stop word removal\n",
    "\n",
    "#### Docs containing many query terms\n",
    "For multi-term queries, only compute scores for docs with multiple query terms.  \n",
    "eg. 3 out of 4 query terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Champion list\n",
    "\n",
    "Pre compute for each dictionary term `t`, the `r` docs of highest weight in t's postings.  \n",
    "So we have some foresight as to what might be most relevant for each query term before user starts using the search engine.\n",
    "\n",
    "- Note that `r` has to be chosen during indexing stage -> thus its possible to have `r`<`K`.\n",
    "\n",
    "At query time, only compute the scores for docs in the champion list for some query terms\n",
    "- pick the K top-scoring docs from amongst there\n",
    "\n",
    "#### High and low list\n",
    "\n",
    "Similar to champion list, we maintain a `high` and `low` list.\n",
    "\n",
    "- When traversing the postings on a query, only traverse `high` list first.\n",
    "- If not enough docs to meet `K` docs, then traverse the `low` list.\n",
    "\n",
    "##### Pros:\n",
    "Can be used even for simple cosine scores without global quality `g(d)`.\n",
    "\n",
    "#### Tiered indexes\n",
    "Generalising `high` and `low` lists into tiers.\n",
    "- We break the postings up into a hierarchy of lists\n",
    "```\n",
    "Most impt\n",
    "...\n",
    "Least impt\n",
    "```\n",
    "- At query time, we only use top tier unless insufficient to get `K` docs. -> if so drop to lower tiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impact-ordered postings\n",
    "\n",
    "We only compute scores for docs with high enough word frequency `Wft,d`.\n",
    "\n",
    "- We sort each postings list by `Wft,d`\n",
    "\n",
    "#### Cons:\n",
    "Not all postings in a common order, concurrent traversal is not possible. -> cannot perform merge operation as usual\n",
    "\n",
    "#### Early termination\n",
    "1. Sort t's postings by descending `Wft,d` value `Wft,d is the weight of term of the doc`\n",
    "2. When traversing t's postings, stop early after a fixed number of docs or `Wft,d` drops below certain *threshold*.\n",
    "3. Take the union of the results from each query term\n",
    "4. Compute only the scores for the docs in the union\n",
    "\n",
    "#### Idf ordered terms\n",
    "\n",
    "1. Look at postings of query terms in order of decreasing idf\n",
    "2. As we update score contribution from each query term, stop if doc scores are relatively unchanged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster pruning (K-means clustering)\n",
    "\n",
    "- Pick sqrt(N) docs at random and call these `centers`\n",
    "- For other docs, pre-compute nearest `center`\n",
    "    - Docs attached to a `center` are its followers\n",
    "    - Each `center` will be likely to have sqrt(N) followers\n",
    "\n",
    "Process a query as follows:\n",
    "- Given a query Q, find the nearest leader L\n",
    "- Seek K nearest docs from among L's followers and L itself\n",
    "\n",
    "#### Pros:\n",
    "- Fast when we choose `centers` at random\n",
    "- `centers` reflect data distribution\n",
    "- Clustering can be done offline (indexing) as well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Incorporating additional information\n",
    "\n",
    "- We want top-ranking documents to be both relevant and authoratative\n",
    "    - Relevance is beign modeled by cosine scores\n",
    "    - Authority is typically a query-independent property of a document\n",
    "\n",
    "- Some examples of authority signals\n",
    "    - Wikipedia among other websites\n",
    "    - Articiles in certain newspapers\n",
    "    - A paper with many citations - quantitative\n",
    "    - Many views, retweets, favourites, likes - quantitative\n",
    "    - PageRank score - quantitative\n",
    "\n",
    "#### Modelling authority\n",
    "We assign a query-independent quality score in [0,1] to each document. Denote this by `g(d)`.\n",
    "\n",
    "#### Net score\n",
    "`net-score(q,d) = g(d) + cos(q,d)` quality is **added** to the pre-existing cosine score  \n",
    "Now we seek top `K` docs by `net-score`\n",
    "\n",
    "#### Top K by net score\n",
    "Fast method: Order all postings by `g(d)`.  \n",
    "Thus we can concurrently traverse query terms' postings for Postings intersection and Cosine score computation.\n",
    "\n",
    "##### Why?\n",
    "Under `g(d)` ordering, top-scoring docs are likely to appear early in postings traversal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combination of concepts\n",
    "Champion list in `g(d)` ordering.  \n",
    "- Maintain for each term a champion list of the `r` docs with highest g(d) + tf-idf instead of just tf-idf.\n",
    "- Seek top `K` results from only the docs in the champion list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parametric and zone indexes\n",
    "Defining parts for documents eg. fields.  \n",
    "These contribute metadata to the document\n",
    "\n",
    "#### Zone indexing\n",
    "\n",
    "A zone is a region of the doc that can contain an arbitrary amount of text eg.\n",
    "- Title\n",
    "- Abstract\n",
    "- References\n",
    "\n",
    "Build inverted indexes on zones as well as permit querying of these zones. eg. `Find merchants in tht title zone and matching the query gentle rain`\n",
    "\n",
    "##### Approach 1\n",
    "```\n",
    "william.abstract: 11 -> 121 -> ...\n",
    "william.title: ...\n",
    "william.author: ...\n",
    "```\n",
    "We encode zones in dictionary  \n",
    "**Pros:**  \n",
    "We can search for specific zones without the need for retrieving all the postings\n",
    "##### Approach 2\n",
    "```\n",
    "william: 2.author, 2.title -> 3.author -> 4.title -> ...\n",
    "```\n",
    "**Pros:**  \n",
    "Postings can have a single Df score accounting for all the documents regardless of zone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query term proximity\n",
    "\n",
    "Heuristic: Users prefer docs where the query terms occur closer to each other.  \n",
    "Let `w` be the smallest window in a doc containing all the query terms\n",
    "\n",
    "### Query parsers\n",
    "\n",
    "Free text query from user may spawn one or more queries to the indexes eg. `NUS open day`\n",
    "#### Steps:\n",
    "\n",
    "1. Run the query as a phrase query\n",
    "2. If <`K` docs contain the phrase `NUS open day`, run the two phrase queries `NUS open` and `open day`.\n",
    "3. If we still have <`K` docs, run the vector space query on `NUS open day`\n",
    "4. Rank matching docs by vector space scoring\n",
    "\n",
    "#### Alternatively: \n",
    "1. We can find the smallest window containing all of the query terms if we can go through all the positional posting's list concurrently\n",
    "2. Then based on the smallest window, we can set the cap `w` to be that instead\n",
    "\n",
    "The sequence is issued by the query parser"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
